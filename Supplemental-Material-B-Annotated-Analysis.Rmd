---
title: "Supplemental Information B: Full Annotated Analysis and Reproducible Code"
subtitle: "Suppplemental Material for 'Psychological Needs During Intergroup Contact [working title]'"
author:
- Jannis Kreienkamp^1,2^
- Maximilian Agostini^1,2^
- Laura Bringmann^1,2^
- Peter de Jonge^1,2^
- Kai Epstude^1,2^
- ^1^University of Groningen, Department of Psychology
- ^2^Author order to be discussed; currently alphabetic by last name
- "Author Information:"
- "Correspondence concerning this article should be addressed to Jannis Kreienkamp, Department of Psychology, University of Groningen, Grote Kruisstraat 2/1, 9712 TS Groningen (The Netherlands).  E-mail: <a href='mailto:j.kreienkamp@rug.nl'>j.kreienkamp@rug.nl</a>"
- 'The main manuscript is available at <a href="https://www.doi.org/ToBePublished" target="_blank">doi.org/ToBePublished</a>'
- 'The data repository for this manuscript is available at <a href="https://osf.io" target="_blank">OSF link goes here</a>'
- 'The GitHub repository for this manuscript is available at <a href="https://janniscodes.github.io/intergroup-contact-needs/" target="_blank">janniscodes.github.io/intergroup-contact-needs/</a>'
date: "Last updated: `r format(Sys.time(), '%d %B, %Y')`"
output: 
  bookdown::html_document2:
    fig_caption: yes
    md_extensions: +footnotes
    code_folding: hide
    mathjax: default
    theme: yeti
    toc: yes
    toc_float: yes
    number_sections: false
    css: style.css
    includes:
      in_header: "_includes/head-custom-rmd.html" 
editor_options:
  chunk_output_type: console
bibliography: references.bib
csl: apa.csl
---

<style type="text/css">
.main-container {
  max-width: 1300px;
  margin-left: auto;
  margin-right: auto;
}
.table {
  margin-left:auto; 
  margin-right:auto;
}
</style>


```{r setup, include=FALSE}
# R Studio Clean-Up
  cat("\014") # clear console
  #rm(list=ls()) # clear workspace - use restart R instead [cmd/alt + shift + F10]
  gc() # garbage collector
  
# Install and Load Packages
# !IMPORTANT!
# BEFORE FIRST RENDER:
# To install all relevant packages please run "renv::restore()" (or renv::init() and then initiate from lockfile) in the console before the first use to ensure that all packages are using the correct version.
# to store the packages in a contained library within the project folder: renv::settings$use.cache(FALSE) and add 'RENV_CONFIG_SANDBOX_ENABLED = FALSE' to an '.Renviron' file 
lib <- c("rmarkdown", "knitr", "remedy", "bookdown", "psych",
         "ggplot2", "ggthemes", "haven", "RColorBrewer", "plotly", "gridExtra", "ggpattern",
         "lme4", "nlme", "jtools", "gtsummary",
         "sessioninfo", "tibble", "pander", "devtools", "mada",
         "data.table", "plyr", "dplyr", "tidyr", "Hmisc", "kableExtra", "papaja",
         "stringr", "stringi", "reshape2", "lubridate")
invisible(lapply(lib, library, character.only = TRUE))  
rm(lib)  

# Load Custom Packages  
  source("./scripts/functions/fun.panel.R")
  source("./scripts/functions/themes.R")
  source("./scripts/functions/binaryCor.R")

# Markdown Options
  knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # set working directory
  knitr::opts_knit$get("root.dir") # check working directory
  options(scipen = 999, digits = 4, width = 400) #removes scientific quotation
  #knitr::opts_chunk$set(echo = TRUE, cache = F, cache.path = rprojroot::find_rstudio_root_file('cache/')) # cache settings
  knitr::knit_hooks$set(
   error = function(x, options) {
     paste('\n\n<div class="alert alert-danger">',
           gsub('##', '\n', gsub('^##\ Error', '**Error**', x)),
           '</div>', sep = '\n')
   },
   warning = function(x, options) {
     paste('\n\n<div class="alert alert-warning">',
           gsub('##', '\n', gsub('^##\ Warning:', '**Warning**', x)),
           '</div>', sep = '\n')
   },
   message = function(x, options) {
     paste('\n\n<div class="alert alert-info">',
           gsub('##', '\n', x),
           '</div>', sep = '\n')
   }
  )
  htmltools::tagList(rmarkdown::html_dependency_font_awesome())

# Global Chunk Options
  knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figures/',
                        echo=TRUE, warning=FALSE, message=FALSE)
```

<br/>

<i class="fas fa-exclamation-circle"></i> Note. Boxplots display the interquartile range (IQR, center box), and the whiskers extend 1.5*IQR from the lower and upper hinge. The white point indicates the mean and the white center line indicates the median.   

<br/>

# **Data Preparation**  

## Data Import  

```{r formrImport}
# workers
# initial data cleaning was done in SPSS (syntax files are available in "")
dtWorker <- list(
  raw.pre = read_spss("data/S1_Workers/processed/cleaned/MT - Pre-Measure - 06-15-2018.sav"),
  raw.post = read_spss("data/S1_Workers/processed/cleaned/MT - Post-Measure - 06-15-2018.sav"),
  raw.morning = read_spss("data/S1_Workers/processed/cleaned/MT - Morning - 06-15-2018.sav"),
  raw.afternoon = read_spss("data/S1_Workers/processed/cleaned/MT - Afternoon - 06-15-2018.sav")
)

# students
dtStudents <- list(
  raw.pre = read.csv(file = "data/S2_Students/raw/AOTS_Pre.csv", header = T, sep = ","),
  raw.post = read.csv(file = "data/S2_Students/raw/AOTS_Post.csv", header = T, sep = ","),
  raw.daily = read.csv(file = "data/S2_Students/raw/AOTS_Daily.csv", header = T, sep = ",")
)

# young medical professionals
dtMedical <- list(
  raw.pre = c(),
  raw.post = c(),
  raw.daily = c()
)

```

## Data Cleaning & Data Exclusions  

```{r cleanWorker}
#  important names for Morning and Afternoon
  names.m <- c(
    "StartDate",
    "EndDate",
    "Finished",
    "Duration__in_seconds_",
    "RecordedDate",
    "ExternalReference",
    "Meta_Operating_System",
    "Contact_dum",
    "number",
    "time",
    "duration_1",
    "dyad.group",
    "gr_size",
    "gr_type_1",
    "gr_type_2",
    "gr_type_3",
    "gr_type_4",
    "gr_type_5",
    "gr_type_6",
    "gr_type_7",
    "gr_type_8",
    "gr_type_9",
    "gr_type_10",
    "gr_type_11",
    "gr_type_12",
    "gr_type_13",
    "gr_type_14",
    "gr_type_15",
    "gr_type_16",
    "gr_type_17_TEXT",
    "gr_context_1",
    "gr_context_2",
    "gr_context_3",
    "gr_context_4",
    "gr_context_5",
    "gr_context_6",
    "gr_context_7",
    "gr_context_8",
    "gr_context_9",
    "gr_context_10",
    "gr_context_11",
    "gr_context_12",
    "gr_context_13_TEXT",
    "gr_context_14_TEXT",
    "gr_dutchness",
    "dyad_type_1",
    "dyad_type_2",
    "dyad_type_3",
    "dyad_type_4",
    "dyad_type_5",
    "dyad_type_6",
    "dyad_type_7",
    "dyad_type_8",
    "dyad_type_9",
    "dyad_type_10",
    "dyad_type_11",
    "dyad_type_12",
    "dyad_type_13",
    "dyad_type_14",
    "dyad_type_15",
    "dyad_type_16",
    "dyad_type_17_TEXT",
    "Context_1",
    "Context_2",
    "Context_3",
    "Context_4",
    "Context_5",
    "Context_6",
    "Context_7",
    "Context_8",
    "Context_9",
    "Context_10",
    "Context_11",
    "Context_12",
    "Context_13_TEXT",
    "Context_14_TEXT",
    "keyMotive",
    "keymotive_fulfillemt_1",
    "keyMotive_Dutch_1",
    "autonomy_1",
    "competence_1",
    "relatedness_self_1",
    "relatedness_other_1",
    "qualityAccidental_1",
    "qualityVoluntary_1",
    "qualityCooperative_1",
    "qualityDutchy_1",
    "quality_overall_1",
    "quality_meaning_1",
    "quality_star_1",
    "wantInt",
    "desire_type_1",
    "desire_type_2",
    "desire_type_3",
    "desire_type_4",
    "desire_type_5",
    "desire_type_6",
    "desire_type_7",
    "desire_type_8",
    "desire_type_9",
    "desire_type_10",
    "desire_type_11",
    "desire_type_12",
    "desire_type_13",
    "desire_type_14",
    "desire_type_15",
    "desire_type_16",
    "desire_type_17_TEXT",
    "desire_context_1",
    "desire_context_2",
    "desire_context_3",
    "desire_context_4",
    "desire_context_5",
    "desire_context_6",
    "desire_context_7",
    "desire_context_8",
    "desire_context_9",
    "desire_context_10",
    "desire_context_11",
    "desire_context_12",
    "desire_context_13_TEXT",
    "desire_context_14_TEXT",
    "Reason_nodesire",
    "keyMotive_noInt",
    "keyMotive_noInt_fulf_1",
    "autonomy_NoInt_1",
    "competence_NoInt_1",
    "relatedness_1_NoInt_1",
    "thermometerDutch_1",
    "thermometerDutchInt_2",
    "ExWB_1",
    "alertness1",
    "calmness1",
    "valence1",
    "alertness2",
    "calmness2",
    "valence2",
    "inNonDutch",
    "NonDutchNum",
    "NonDutchType_1",
    "NonDutchType_2",
    "NonDutchType_3",
    "NonDutchType_4",
    "NonDutchType_5",
    "NonDutchType_6",
    "NonDutchType_7",
    "NonDutchType_8",
    "NonDutchType_9",
    "NonDutchType_10",
    "NonDutchType_11",
    "NonDutchType_12",
    "NonDutchType_13",
    "NonDutchType_14",
    "NonDutchType_15_TEXT",
    "date",
    "time.0",
    "LocationLatitude",
    "LocationLongitude"
  )
  
  names.a <- c(names.m, "keyInteraction_1", "keyInteractionTime")

# Create reduced data sets for morning and afternoon
  dat.mo <- dtWorker$raw.morning[, names.m]
  dat.mo$daytime <- "morning"
  
  dat.af <- dtWorker$raw.afternoon[, names.a]
  dat.af$daytime <- "afternoon"

# merge morning and afternoon measurements with indicator [+ clean up]
  daily.dat <- rbind.fill(dat.mo, dat.af)
  daily.dat <- daily.dat[daily.dat$ExternalReference != 55951, ]
  dtWorker$daily <- daily.dat
  rm(dat.mo, dat.af, names.m, names.a, daily.dat)


# names for pre-measurement
  names.pre <- c(
    "Finished",
    "age",
    "Gender",
    "Living",
    "roommate_1",
    "roommate_2",
    "roommate_3",
    "nationality",
    "SecondNationality",
    "timeNL_1",
    "Reason_2",
    "Reason_5",
    "Reason_7",
    "Reason_8_TEXT",
    "DutchLang",
    "occupation_1",
    "occupation_2",
    "occupation_3",
    "occupation_4",
    "occupation_7",
    "CurrentEducation_1",
    "education_level",
    "EduLang_2",
    "RUG_faculty",
    "Study.0",
    "association",
    "DutchMeetNum",
    "DutchFriends_1",
    "assimilation",
    "separation",
    "integration",
    "marginalization",
    "VIA_heritage",
    "VIA_Dutch",
    "SSAS_surrounding",
    "SSAS_privat",
    "SSAS_public",
    "autonomy",
    "relatedness",
    "competence",
    "anxiety",
    "swl",
    "alertness",
    "calmness",
    "valence",
    "date",
    "time",
    "City",
    "ZIP",
    "id"
  )
  
# reduced data set for pre measurement
  dat.pre.red <- dtWorker$raw.pre[, names.pre]

# merge with daily data [+ clean up]
  df.pre <- merge(
    x = dtWorker$daily,
    y = dat.pre.red,
    by.x = "ExternalReference",
    by.y = "id",
    all = T
  )
  rm(names.pre)

# adjust duplicate names to fit to indicate daily or pre measurement  
  names(df.pre) <- gsub("[[:punct:]]x", ".daily", names(df.pre))
  names(df.pre) <- gsub("[[:punct:]]y", ".pre", names(df.pre))

# names for post measurement  
  names.post <- c(
    "ExternalReference",
    "assimilation",
    "separation",
    "integration",
    "marginalization",
    "VIA_heritage",
    "VIA_Dutch",
    "anxiety",
    "swl",
    "rosenberg",
    "social_support",
    "stress",
    "discrimination",
    "discrimination_month",
    "NLE_1month",
    "NLE_6month",
    "NLE_12month"
  )

# reduced data set for post-measurement  
  dat.post.red <- dtWorker$raw.post[, names.post]

# merge post measurement with pre- and daily data  
  df <- merge(
    x = df.pre,
    y = dat.post.red,
    by.x = "ExternalReference",
    by.y = "ExternalReference",
    all = T
  )

# adjust duplicate names to indicate pre or post  
  names(df) <- gsub("[[:punct:]]x", ".pre", names(df))
  names(df) <- gsub("[[:punct:]]y", ".post", names(df))
  
# add to list
  dtWorker$combined <- df
  
# create data frame with cleaned data
  df <- dtWorker$combined %>%
    filter(Finished.pre == 1,
           Finished.daily == 1,
           !is.na(ExternalReference))

# add running number as measurement ID within participants   
  df$measureID = rowidv(df, cols = c("ExternalReference"))
  
  df <- df %>%
    mutate(
      PID = as.numeric(factor(ExternalReference)), # participant ID
      TID = measureID-1, # time ID with t0 = 0 for meaningfull intercept interpretations
      date = substr(StartDate,1,10), # awkward way of extracting date (best converted to )
      time = substr(StartDate,12,19), # awkward way of extracting time
      daynum = as.numeric(factor(date)), # all days as numeric for ordering
      daycor = ifelse(daytime=="morning" & period_to_seconds(hms(time))<period_to_seconds(hms("12:00:00")) | daytime=="afternoon" & period_to_seconds(hms(time))<period_to_seconds(hms("19:00:00")),daynum-1,daynum), # correctly identify which date the questionnaire is about
      daycor.lead = sprintf("%02d", daycor),
      daytime.lt = ifelse(daytime=="morning","a","b"), # morning / afternoon to a / b 
      day_time = paste(daycor.lead, daytime.lt, sep="_"), # combine day id with morning / afternoon
      session = as.numeric(factor(day_time)), # day and time identifier as numeric id
      SubTime = chron::times(time.0),
      time.daily = as.character(time.daily),
      PPDate = as.Date(df$date.daily),
      number = replace_na(number, 0),
      NonDutchNum = replace_na(NonDutchNum, 0)
    )
  
  dtWorker$clean <- df
  
# clean up
  rm(df.pre, names.post, dat.post.red, dat.pre.red, df)

# Export reduced Data
  #write.csv(dtWorker$clean, "data/processed/MT_clean-merged_07-05-2018.csv", row.names = F)
  #save(dtWorker$clean, file = "data/processed/MT_clean-merged_07-05-2018.RData")
```

```{r cleanStudents}
# our own test IDs
ownIDs <- c(
  "beautifulLionfishXXXR5rcgVBzGu8hPvOqrK8UBJBw4owvi9nfRFSFu3lMzYhE",
  "niceDogoXXXmB8JI5SFu78SF3DVof84mGUPPNUr14p2HYFTtp31a6D1OwAzM6F-K",
  "amusedQuailXXXmhuc_fpTp8vPkMwDH1BzjaH1d1kHSO1bsPEfsnaEYk4WeVBfPi",
  "juwGAbtXX0_1kmZtSVqKh3PGaHOICqUyU4iBkrT3nDsI_uifuD1gzKcZerxaM5FL"
)

# Prepare dfs for Cleaning
df.pre <- dtStudents$raw.pre %>%
  mutate_all(na_if,"") %>%
  mutate_all(na_if,"NA") %>%
  filter(!is.na(ended)) %>% # remove all who did not finish
  filter(!e_mail %in% .$e_mail[duplicated(.$e_mail)]) %>% # remove all who did the pre questionnaire multiple times (b/c inconsistent ratings scales)
  filter(!session %in% ownIDs) %>% # remove our own test 
  mutate(session = as.character(session)) # turn factor into character strings (probably just precaution)

df.post <- dtStudents$raw.post %>%
  mutate_all(na_if,"") %>%
  mutate_all(na_if,"NA") %>%
  filter(!is.na(session)) %>% # remove own test runs
  filter(!session %in% ownIDs) %>% # remove our own test 
  filter(session %in% df.pre$session) %>% # remove anyone who wasn't in the pre
  filter(!is.na(ended)) %>% # remove all who never finished
  filter(!session %in% .$session[duplicated(.$session)]) %>% # remove all duplicate sessions
  mutate(session = as.character(session)) # turn factor into character strings (probably just precaution)

df.daily <- dtStudents$raw.daily %>%
  mutate_all(na_if,"") %>%
  mutate_all(na_if,"NA") %>%
  filter(!session %in% ownIDs) %>% # remove our own test 
  filter(session %in% df.pre$session) %>% # remove anyone who wasn't in the pre
  filter(!is.na(ended)) %>% # remove all who never finished
  mutate(session = as.character(session)) # turn factor into character strings (probably just precaution)

# merge daily with pre
dfPreDaily = merge(
  x = df.daily,
  y = df.pre,
  by = "session",
  suffixes = c(".daily", ".pre"),
  all = F
)
  
# merge daily with post 
dfCombined = merge(
  x = dfPreDaily,
  y = df.post,
  by = "session",
  suffixes = c(".pre", ".post"),
  all = F
)

# add to list
dtStudents$clean <- dfCombined 

# clean up workspace
rm(df.pre, df.daily, df.post, dfPreDaily, dfCombined, ownIDs)
```

```{r cleanMedical}
#TBD
```

## Calculate needed transformations  

```{r newVarsWorkers}
df <- dtWorker$clean

# Time and Date Variables
  # remove seconds from afternoon time
  df$SubTime[df$daytime == "afternoon"] = paste0(substring(as.character(df$time.0[df$daytime == "afternoon"]),4,8),":00") 
  df$time.daily[df$daytime == "afternoon" & !is.na(df$time.daily!="<NA>")] = paste0(substring(as.character(df$time.daily[df$daytime == "afternoon" & !is.na(df$time.daily!="<NA>")]),4,8),":00")
  
  # Correct morning / afternoon date where survey was collected the day after to indicate the correct date that was targeted
  df$PPDate[df$SubTime < "11:50:00" & df$daytime == "morning"] = df$PPDate[df$SubTime < "11:50:00" & df$daytime == "morning"]-1
  df$PPDate[df$SubTime < "18:50:00" & df$daytime == "afternoon"] = df$PPDate[df$SubTime < "18:50:00" & df$daytime == "afternoon"]-1
  
# Mood scales
  df$calmness.daily = rowSums(df[, c("calmness1", "calmness2")], na.rm = T)
  df$alertness.daily = rowSums(df[, c("alertness1", "alertness2")], na.rm =T)
  df$valence.daily = rowSums(df[, c("valence1", "valence2")], na.rm = T)
  
# Need scales
  df$keyMotiveFulfilled = rowSums(df[,c("keymotive_fulfillemt_1","keyMotive_noInt_fulf_1")], na.rm=T)
  df$autonomy.daily.all = rowSums(df[,c("autonomy_1","autonomy_NoInt_1")], na.rm=T)
  df$competence.daily.all = rowSums(df[,c("competence_1","competence_NoInt_1")], na.rm=T)
  #cor(df$relatedness_other_1, df$relatedness_self_1,use="complete.obs")
  df$relatedness.daily.all = rowMeans(df[,c("relatedness_other_1","relatedness_self_1","relatedness_1_NoInt_1")], na.rm=T)
  df$relatedness.daily.int = rowMeans(df[,c("relatedness_other_1","relatedness_self_1")], na.rm=T)

# summarize by participant (check that everything is within pp might not be the case for )
  between <- df %>%
    group_by(ExternalReference) %>%
    mutate(
      CtContactNL = sum(Contact_dum),
      CtContactNonNl = sum(inNonDutch),
      CtContactNLAll = sum(number),
      CtContactNonNlAll = sum(NonDutchNum),
      AvKeyNeed = mean(keyMotiveFulfilled, na.rm=T),
      AvKeyNeedInt = mean(keymotive_fulfillemt_1, na.rm=T),
      AvKeyNeedNoInt = mean(keyMotive_noInt_fulf_1, na.rm=T),
      AvAutonomy = mean(autonomy.daily.all, na.rm=T),
      AvCompetence = mean(competence.daily.all, na.rm=T),
      AvRelatedness = mean(relatedness.daily.all, na.rm=T),
      AvThermo = mean(thermometerDutch_1, na.rm=T),
      AvWB = mean(ExWB_1, na.rm=T)) %>%
    ungroup() %>%
    mutate(
      CtContactNL_c = scale(CtContactNL, scale = FALSE),
      AvKeyNeedInt_c = scale(AvKeyNeedInt, scale = FALSE),
      AvKeyNeed_c = scale(AvKeyNeed, scale = FALSE),
      CtContactNL_z = scale(CtContactNL, scale = TRUE),
      AvKeyNeedInt_z = scale(AvKeyNeedInt, scale = TRUE),
      AvKeyNeed_z = scale(AvKeyNeed, scale = TRUE)
    ) 
  
  warning("some variable transformations (esp. _c and _z) might be across all participants (i.e., not within PP).")
  
  dtWorker$full <- between
  
  rm(df, between)
  
  #save(df.btw, file = "data/processed/df.btw.RData")  
  #write_sav(df.btw, "data/processed/MT_clean-merged_pre-post.sav")
  
# export data to Mplus
  # df.mplus = remove_all_labels(select(df, PID, session, thermometerDutch_1, inNonDutch, Contact_dum, keyMotiveFulfilled, autonomy.daily.all, competence.daily.all, relatedness.daily.all))
  # names(df.mplus)= c("PID", "session", "att", "intin", "intout", "keymot", "aut", "comp", "rel")
  # mplus = df.mplus[order(df.mplus$PID, df.mplus$session),]
  # mplus.intcont = mplus[mplus$intout==1,]
  # prepareMplusData(mplus.intcont, "data/processed/dynamic-subset-intonly.dat")

```


```{r newVarsStudents}
df <- dtStudents$clean

# Add ID variables
  df$PID = as.numeric(factor(df$session)) # participant ID

# order time
  df$TID <- factor(df$date_period, levels = unique(dtStudents$raw.daily$date_period))
  df$TIDnum <- as.numeric(df$TID) #get numeric TID
  
  # check whether time ordering worked
  df <- df %>%
    arrange(PID, TID) #%>%
    #View()
  
# Interaction as Factor
  df$interaction.f <- factor(df$Interaction, levels = c("no interaction", "Dutch", "Non-Dutch"))
  df$intNL <- ifelse(df$Interaction=="Dutch",1,0)
  df$intNonNL<- ifelse(df$Interaction=="Non-Dutch",1,0)
   
# ------------------------------------------------------------------------------------------------------------- 
#                                       Combine Variables
# -------------------------------------------------------------------------------------------------------------
# Relatedness
  pairs.panels.new(df[c("RelatednessSelf","RelatednessOther")], 
                              labels = c("I shared information about myself.", "X shared information about themselves."))
  df$RelatednessInteraction <- rowMeans(df[c("RelatednessSelf","RelatednessOther")], na.rm=T)
  df$RelatednessInteraction[df$RelatednessInteraction == "NaN"] <- NA
# Relatedness Overall (JANNIS NOT SURE THESE ARE CORRECT, CHANGE ROWS?; J: Changed "NaN" in df$RelatednessInteraction to NA() should work now)
  df$Relatedness <- rowMeans(df[,c("RelatednessInteraction", "RelatednessNoInteraction")], na.rm=T)
# Pro-Sociality
  df$ProSo <- rowMeans(df[,c("ProSo1", "ProSo2", "ProSo3", "ProSo4")], na.rm=T)
# Anti-Sociality
  df$AntiSo <- rowMeans(df[,c("AntiSo1", "AntiSo2", "AntiSo3", "AntiSo4")], na.rm=T)


# ------------------------------------------------------------------------------------------------------------- 
#                                 Add Variables related to interaction partner
# -------------------------------------------------------------------------------------------------------------
# create function for later lapply
createIntPartDf <- function(inp) {
  
  # prepare the dataframe so that we can forloop over it later
    tmp <- data.frame(CC = as.character(inp$CC),
                    NewCC = as.character(inp$NewCC),
                    NewName = as.character(inp$NewName),
                    NewCloseness = inp$NewCloseness,
                    NewGender = inp$NewGender,
                    NewEthnicity = as.character(inp$NewEthnicity),
                    NewRelationship = as.character(inp$NewRelationship))
    
    tmp$CC2 <- recode(tmp$CC, 'SOMEONE ELSE' = "NA")
    tmp$CC2 <- ifelse(tmp$CC == 1 | tmp$CC == "SOMEONE ELSE", as.character(tmp$NewName), as.character(tmp$CC2)) 
    # maybe add [[:space:]]\b to remove space before word boundary or ^[[:space:]] to remove space in the beginning of a string
    tmp$CC2 <- gsub("^[[:space:]]", "", tmp$CC2)
    tmp$NewName <- gsub("^[[:space:]]", "", tmp$NewName)
    
  # open the variables that will be filled up in the foor-loop
    tmp$closeness <- rep(NA, nrow(tmp))
    tmp$gender <- rep(NA, nrow(tmp))
    tmp$ethnicity <- rep(NA, nrow(tmp))
    tmp$relationship <- rep(NA, nrow(tmp))
  
    # Run the for-loop. It finds the variables related to the name of the interaction partner. If there is a repeating interaction
    # partner (i.e. CC2) it takes the value (i.e. NewCloseness) from the first interaction (i.e. NewName)
      for (i in 1:nrow(tmp)) {
         if (is.na(tmp$CC2[i])) {
           next
         } else {
           tmp$closeness[i] <- na.omit(tmp$NewCloseness[as.character(tmp$CC2[i]) == as.character(tmp$NewName)])[1] #find closeness where CC2 matches NewName (na.omit + [1] to get the number)
           tmp$gender[i] <- na.omit(tmp$NewGender[as.character(tmp$CC2[i]) == as.character(tmp$NewName)])[1] #(na.omit + [1] to get the number and not the rest of the na.omit list)
           tmp$ethnicity[i] <- na.omit(as.character(tmp$NewEthnicity[as.character(tmp$CC2[i]) == as.character(tmp$NewName)]))[1] #PROBLEM IS THAT THERE ARE TOO MANY NA's: Difficult to deal with
           tmp$relationship[i] <- na.omit(as.character(tmp$NewRelationship[as.character(tmp$CC2[i]) == as.character(tmp$NewName)]))[1]
         }
      }
      
    out <- tmp
    out
}

# split df per participants and run function
  PP <- split(df, df$PID)
  PP <- lapply(PP, createIntPartDf); rm(createIntPartDf)
  
# add variables back to df
  remergePP <- do.call(rbind.data.frame, PP)
    colnames(remergePP) <- paste(colnames(remergePP), "_Calc", sep = "")
df <- cbind(df, remergePP);rm(remergePP)

# ------------------------------------------------------------------------------------------------------------- 
#                                 Center Relevant Variables
# -------------------------------------------------------------------------------------------------------------

df <- df %>%
  group_by(PID) %>% 
  mutate(
    KeyNeedFullfillment.cm = mean(KeyNeedFullfillment, na.rm = TRUE), # cluster mean (mean of PP)
    KeyNeedFullfillment.cwc = KeyNeedFullfillment - KeyNeedFullfillment.cm, # cluster mean centered (within PP centered)
    closeness.cm = mean(closeness_Calc, na.rm = TRUE),
    closeness.cwc = closeness_Calc - closeness.cm
    ) %>%  
  ungroup()

# store
  dtStudents$full = df
```

```{r newVarsMedical}
# TBD
```

# **Worker Sample**

## Data Description

<i class="fas fa-exclamation-triangle"></i> Still in 'scr/workerDescriptive.R'. Needs to be merged with this document.

## Contact Hypothesis

### Interaction Frequency and Outgroup Attitudes

\begin{equation}
(\#eq:WorkerFreqQualR)
r_{ContactFrequency, OutgroupAttitudes} \neq 0
\end{equation}

```{r WorkerFreqAttCor}
# prepare data
workerContactFreq <- dtWorker$full %>% 
  group_by(ExternalReference) %>%
  summarise(
    n = n(),
    SumContactNL = sum(Contact_dum),
    PercContactNL = SumContactNL/n*100,
    SumContactNLAll = sum(number),
    AvAttitude = mean(thermometerDutch_1, na.rm=T)
  ) %>%
  mutate(
    WinSumContactNL = DescTools::Winsorize(SumContactNL),
    WinSumContactNLAll = DescTools::Winsorize(SumContactNLAll)
  )

# correlation panel 
pairs.panels.new(workerContactFreq %>% select(SumContactNL, SumContactNLAll, AvAttitude), 
                 labels = c("Sum:\nNumer of beeps with Outgroup Contact (NL)", 
                            "Sum:\nNumber of Outgroup Contacts (NL)", 
                            "Mean:\nOutgroup Attitudes (NL)"))

# correlation panel with interaction sums winsorized
pairs.panels.new(workerContactFreq %>% select(WinSumContactNL, WinSumContactNLAll, AvAttitude), 
                 labels = c("Sum:\nNumer of beeps with Outgroup Contact (NL)\n[Winsorized]", 
                            "Sum:\nNumber of Outgroup Contacts (NL)\n[Winsorized]", 
                            "Mean:\nOutgroup Attitudes (NL)"))
```

TL;DR: Neither the number of interactions nor the number of measurement beeps with an interaction are significantly related with the average outgroup attitudes. This is to say that within our data participants with more outgroup interactions did not have significantly more positive outgroup attitudes. This might be due to the aggregation within the participants or the small sample size of between participant data. Nonetheless, the aggregate data does not support the notion that simply having more interactions with an outgroup results in more positive outgroup attitudes.

### Outgroup Attitudes by Interaction Type

\begin{equation}
(\#eq:WorkerIntTypeQual)
\mu_{i,0utgroupInteraction} > \mu_{i,IngroupInteraction}  \\
Attitude = OutgroupInteraction \times NonOutgroupInteraction
\end{equation}


<div class="alert alert-info alert-dismissible fade in" role="alert">
  <a class="close" data-dismiss="alert" aria-label="close">&times;</a>
  <i class="fas fa-exclamation-triangle"></i> <b>Note: </b><br/>
  mean difference alone probably even more stupid than only ignoring nested data, because we drop lots of data unnecessarily.  
  And only outgroup interaction Yes / No also weird because interaction group includes people who had only an outgroup interaction and those who also had an interaction with a non-outgroup person, and the no outgroup interaction group includes those who had no interaction at all and those who had an interaction with a non-outgroup person (but no outgroup interaction).
</div>

#### Regression with interaction term

Across participants: impact of different interaction types [probably meaningless because ignores response sets between participants]

```{r workerInteractionTypePlt, fig.height=12}
workerContactType <- dtWorker$full %>% 
  group_by(
    Contact_dum,
    inNonDutch
    ) %>%
  summarise(
    n = n(),
    AttitudeM = mean(thermometerDutch_1, na.rm=T),
    AttitudeSD = sd(thermometerDutch_1, na.rm=T),
    AttitudeSE = AttitudeSD/sqrt(n),
    AttitudeLwr = AttitudeM - 1.96*AttitudeSE,
    AttitudeUpr = AttitudeM + 1.96*AttitudeSE
  ) %>%
  ungroup %>%
  mutate(
    InteractionType = paste(
      ifelse(Contact_dum == 1, "Out", "NoOut"),
      ifelse(inNonDutch == 1, "In", "NoIn"),
      sep = ", "
    )
  )

ggplot(workerContactType, aes(y = AttitudeM, x = as_factor(Contact_dum), fill = as_factor(inNonDutch))) +
  geom_bar(stat = "identity", 
                   color = "black", 
                   position=position_dodge()) +
  geom_errorbar(aes(ymin=AttitudeM, ymax=AttitudeUpr), width=.2,
                 position=position_dodge(.9)) +
  labs(
    fill = "Non-Outgroup Interaction",
    x = "Outgroup Interaction",
    y = "Outgroup Attitude",
    title = "Outgroup Attitudes by Interaction Type [95% CI]"
  ) +
  scale_fill_grey(
    start = 0.2,
    end = 0.8
    ) +
  scale_y_continuous(
    limits = c(0, 100),
    breaks = c(0, 15, 30, 40, 50, 60, 70, 85, 100),
    labels = c("Very cold or unfavorable feelings 0°", 
               "Quite cold and unfavorable feelings 15°", 
               "Fairly cold and unfavorable feelings 30°", 
               "A bit cold and unfavorable feelings 40°", 
               "No feeling at all 50°", 
               "A bit warm and favorable feelings 60°", 
               "Fairly warm and favorable feelings 70° ", 
               "Quite warm and favorable feelings 85° ", 
               "Very warm and favorable feelings 100° ")
  ) +
  theme_Publication()
```

```{r workerInteractionTypeReg}
# prepare dataframe
workerInteractionType <- dtWorker$full %>%
  mutate(
    OutgroupInteraction = as_factor(Contact_dum),
    NonOutgroupInteraction = as_factor(inNonDutch)
  )

# regression
lmWorkerInteraction <- lm(thermometerDutch_1 ~ OutgroupInteraction * NonOutgroupInteraction, data = workerInteractionType)
#summary(lmWorkerInteraction)
# apa_table(
#   apa_print(lmWorkerInteraction)$table, 
#   caption = "Regression across all measurement points [ignoring nested data]."
# ) 

summ(
  lmWorkerInteraction,
  confint = TRUE, 
  digits = 3,
  center = TRUE
     )
```

TL;DR: While controlling for interactions with non-Dutch people, outgroup attitudes were significantly higher when participants had an interaction with a Dutch person. The effect is relatively small (`r format(round(lmWorkerInteraction$coefficients["OutgroupInteractionYes"], 2), nsmall=2)` points on a 0--100 scale). More importantly, however, this analysis lumps all ESM beeps from every participants together and ignores that the data is nested within participants.

#### ML Regression with interaction term

##### Unconditional model

make a model with only the data but a random intercept (unconditional model)   

\begin{equation}
(\#eq:WorkerEmptyModel)
Attitude_{ti} = \gamma_{00} + u_{0i} + e_{ti} \\
\textrm{with}\ u_{0i} \sim \mathcal{N}(0,\tau_{00}^2)\ \textrm{and}\ e_{ti} \sim \mathcal{N}(0,\sigma^2)
\end{equation}

```{r Worker.Null.Model.ML}
df <- dtWorker$full
# Create and save Model
  Null.ML.r = lme4::lmer(thermometerDutch_1~1 + (1|PID),data=df) #use optim if it does not converge
  Null.ML = lme(thermometerDutch_1~1,random=~1|PID,data=df, control=list(opt="nlmimb")) #use optim if it does not converge

# Get summary with p-values (Satterthwaite's method)
  #summary(Null.ML.r) #or with the lme function
  summ(Null.ML.r, digits = 3, center = TRUE)
  
# generate 95% parametric bootstrap CIs (and save them as a csv-file):
  #write.csv(confint(lmer(thermometerDutch_1~1 + (1|PID),data=df),
  #                  method="boot",nsim=1000, 
  #                  parallel = "multicore", ncpus = 4, seed = 42),
  #          "output/tables/ML-Null-CI.csv")

# Save variances
  v.null <- VarCorr(Null.ML) # save variances
# The estimate of (between-group or Intercept variance, tau_{00}^2):
  tau <- as.numeric(v.null[1])
# and the estimate of (within-group or residual variancel, sigma^2) is:
  sigma <- as.numeric(v.null[2])
# The ICC estimate (between/between+within) is:
  ICC <- (as.numeric(v.null[1])/(as.numeric(v.null[1])+as.numeric(v.null[2])))
  ICC.Perc <- ((as.numeric(v.null[1])/(as.numeric(v.null[1])+as.numeric(v.null[2]))))*100
```

ICC $\tau_{00}^2 / (\tau_{00}^2 + \sigma^2)$: The ratio of the between-cluster variance to the total variance is called the Intraclass Correlation. It tells you the proportion of the total variance in Y that is accounted for by the clustering. (In this case the clustering means clustering observations per participant)  

compare the random intercept model to a model without a random intercept (i.e., without levels at all)  

```{r Null.Model.GLS}
# Create and save Model
  Null.gls <-  gls(thermometerDutch_1~1,data=df, control=list(opt="nlmimb"))

# calculate Deviances manually:
  Deviance.gls <- logLik(Null.gls)*-2
  Deviance.null <- logLik(Null.ML)*-2

# Compare the two null models:
  anova(Null.gls, Null.ML) %>%
    as.data.frame %>%
    select(-call) %>%
    kbl(., 
        #label = "",
        caption = "Worker: Model Comparison",
        format = "html", 
        linesep = "",
        booktabs = T,
        align = rep('c', ncol(.)),
        digits = 3)  %>%
  kable_styling(position = "left")
```

We find that an estimated `r format(round(ICC.Perc, 2), nsmall=2)`% of the variation in Feeling Thermometer scores is explained by between participant differences (clustering by PID). This is to say that `r format(round(ICC.Perc, 2), nsmall=2)`% of the variance in any individual report of Attitudes towards the Dutch can be explained by the properties of the individual who provided the rating. And we find that including 'participant' as a predictor adds significantly to the model.

##### Add level one predictors

\begin{equation}
(\#eq:WorkerInteractionTypeModel)
Attitude_{ti} = \gamma_{00} + \gamma_{10}OutgroupInteraction_{ti} + \gamma_{10}NonOutgroupInteraction_{ti} + u_{0i} + e_{ti} \\
\textrm{with}\ u_{0i} \sim \mathcal{N}(0,\tau_{00}^2)\ \textrm{and}\ e_{ti} \sim \mathcal{N}(0,\sigma^2)
\end{equation}

```{r interactionType}
# Create and save Model
  model.int = lme(thermometerDutch_1 ~ OutgroupInteraction + NonOutgroupInteraction, random=~1|PID,data=workerInteractionType)

# Get summary with p-values (Satterthwaite's method)
  summ(lmer(thermometerDutch_1 ~ OutgroupInteraction + NonOutgroupInteraction + (1|PID),data=workerInteractionType), 
       confint = TRUE, digits = 3, center = TRUE)

# Generate 95% parametric bootstrap CIs (and save them as a csv-file):
  #write.csv(confint(lmer(thermometerDutch_1 ~ Contact_dum + inNonDutch + (1|PID),data=df), 
  #                  method="boot",nsim=1000, parallel = "multicore", 
  #                  ncpus = 4, seed = 42),
  #          "output/tables/ML-Inter-CI.csv")

# Compare new model to previous step
  anova(Null.ML, model.int) %>%
    as.data.frame %>%
    select(-call) %>%
    kbl(., 
        #label = "",
        caption = "Worker: Model Comparison",
        format = "html", 
        linesep = "",
        booktabs = T,
        align = rep('c', ncol(.)),
        digits = 3)  %>%
  kable_styling(position = "left")

# Save variances
  v.int <- lme4::VarCorr(model.int) 

# The estimate of between-group (or Intercept variance) explained: 
  # Variance Explained = 1 – (Var with Predictor/Var without Predictor)
    v.int.btw <- 1 - (as.numeric(v.int[1])/as.numeric(v.null[1]))
    v.int.btw.perc <-  (1 - (as.numeric(v.int[1])/as.numeric(v.null[1])))*100
  # and the estimate of within-group (or residual variancel) explained is:
    v.int.within <- 1 - (as.numeric(v.int[2])/as.numeric(v.null[2]))
    v.int.within.perc <- (1 - (as.numeric(v.int[2])/as.numeric(v.null[2])))*100
```

tl;dr: Interaction with Dutch is great predictor, interactions with non-Dutch is not.

\begin{equation}
(\#eq:interactionTypeInteractionEq)
Attitude_{ti} = \gamma_{00} + \gamma_{10}OutgroupInteraction_{ti} \times \gamma_{10}NonOutgroupInteraction_{ti} + u_{0i} + e_{ti} \\
\textrm{with}\ u_{0i} \sim \mathcal{N}(0,\tau_{00}^2)\ \textrm{and}\ e_{ti} \sim \mathcal{N}(0,\sigma^2)
\end{equation}

```{r interactionTypeInteraction}
# Create and save Model
  model.intX = lme(thermometerDutch_1 ~ OutgroupInteraction * NonOutgroupInteraction, random=~1|PID,data=workerInteractionType)

# Get summary with p-values (Satterthwaite's method)
  summ(lmer(thermometerDutch_1 ~ OutgroupInteraction * NonOutgroupInteraction + (1|PID),data=workerInteractionType), 
       confint = TRUE, digits = 3, center = TRUE)

# Generate 95% parametric bootstrap CIs (and save them as a csv-file):
  #write.csv(confint(lmer(thermometerDutch_1 ~ Contact_dum + inNonDutch + (1|PID),data=df), 
  #                  method="boot",nsim=1000, parallel = "multicore", 
  #                  ncpus = 4, seed = 42),
  #          "output/tables/ML-Inter-CI.csv")

# Compare new model to previous step
  anova(model.int, model.intX) %>%
    as.data.frame %>%
    select(-call) %>%
    kbl(., 
        #label = "",
        caption = "Worker: Model Comparison",
        format = "html", 
        linesep = "",
        booktabs = T,
        align = rep('c', ncol(.)),
        digits = 3)  %>%
  kable_styling(position = "left")

# Save variances
  v.intX <- lme4::VarCorr(model.intX) 

# The estimate of between-group (or Intercept variance) explained: 
  # Variance Explained = 1 – (Var with Predictor/Var without Predictor)
    v.intX.btw <- 1 - (as.numeric(v.intX[1])/as.numeric(v.int[1]))
    v.intX.btw.perc <-  (1 - (as.numeric(v.intX[1])/as.numeric(v.int[1])))*100
  # and the estimate of within-group (or residual variancel) explained is:
    v.intX.within <- 1 - (as.numeric(v.intX[2])/as.numeric(v.int[2]))
    v.intX.within.perc <- (1 - (as.numeric(v.intX[2])/as.numeric(v.int[2])))*100
```

TL;DR: Interaction term does not add anything at all.

##### Check for Random Slopes

\begin{equation}
(\#eq:RandSlopesEq)
Attitude_{ti} = \gamma_{00} + \gamma_{10}OutgroupInteraction_{ti} + \gamma_{10}NonOutgroupInteraction_{ti} + u_{0i} + u_{1i} + e_{ti}  \\
\textrm{with}\ \begin{bmatrix} u_{0i}\\ u_{1i}\end{bmatrix} \sim \mathcal{N}(0,\Omega_u): \Omega_u=\begin{bmatrix} \tau_{0}^2 & \\ \tau_{01} & \tau_{1}^2 \end{bmatrix} \textrm{and}\ e_{ti} \sim \mathcal{N}(0,\sigma^2)
\end{equation}

```{r RandSlopes}
# Create and save Model (optimizer needed to reach convergence)
  model.ran = lme(thermometerDutch_1~
                         OutgroupInteraction + NonOutgroupInteraction, 
                         random=~1+OutgroupInteraction+NonOutgroupInteraction|PID,
                       control=lmeControl(opt='optim'), data=workerInteractionType)

# Get summary with p-values (Satterthwaite's method) [+ save model for plotting]
  summ(model.ran0 <- lmer(thermometerDutch_1 ~
                           OutgroupInteraction + NonOutgroupInteraction + 
                           (1+OutgroupInteraction+NonOutgroupInteraction|PID), 
                         data=workerInteractionType), 
       confint = TRUE, digits = 3, center = TRUE)
  
# Generate 95% parametric bootstrap CIs (and save them as a csv-file):
  #write.csv(confint(model.ran0,
  #               method="boot",nsim=1000, 
  #               parallel = "multicore", ncpus = 4, seed = 42),
  #          "output/tables/ML-RandomSlopes-CI.csv")

# Compare new model to previous step
  anova(model.int, model.ran) %>%
    as.data.frame %>%
    select(-call) %>%
    kbl(., 
        #label = "",
        caption = "Worker: Model Comparison",
        format = "html", 
        linesep = "",
        booktabs = T,
        align = rep('c', ncol(.)),
        digits = 3)  %>%
  kable_styling(position = "left")

# Save variances
  v.ran = lme4::VarCorr(model.ran)

# The estimate of between-group (or Intercept variance) explained: 
  # Variance Explained = 1 – (Var with Predictor/Var without Predictor)
    v.ran.btw <- 1 - (as.numeric(v.ran[1])/as.numeric(v.int[1]))
    v.ran.btw.perc <-  (1 - (as.numeric(v.ran[1])/as.numeric(v.int[1])))*100
  # and the estimate of within-group (or residual variancel) explained is:
    v.ran.within <- 1 - (as.numeric(v.ran[2])/as.numeric(v.int[2]))
    v.ran.within.perc <- (1 - (as.numeric(v.ran[2])/as.numeric(v.int[2])))*100

# Assumption Checks: 
  diag = sjPlot::plot_model(model.ran0, type = "diag")
  grid.arrange(diag[[1]],diag[[2]]$`PID`,diag[[3]],diag[[4]])
  
# Plot prediction model
  dat.new = workerInteractionType[,c("thermometerDutch_1","session","PID")]
  dat.new$measure = predict(model.ran, workerInteractionType, re.form=NA)

  (t.ppt = ggplot(data=dat.new, aes(x=session, y=measure)) + 
    geom_line(alpha=1, color = "blue") +
    geom_line(aes(y = thermometerDutch_1), alpha=1)+
    facet_wrap(~PID, ncol = 6)+
    xlab("Time")+
    ylab("Outgroup Attitudes")+
    theme_bw())
  ggsave(filename = "Figures/Development per PPT.png", t.ppt,
       width = 18, height = 12, dpi = 800, units = "cm", device='png')
  
  rm(dat.new)

```

TL;DR: Random slopes don't add much for this super simple model.

### Interaction Frequency and Interaction Quality

\begin{equation}
(\#eq:FreqQual)
Attitude = ContactFreq \times AverageContactQual
\end{equation}

```{r WorkerFreqQualCor}
# prepare data
workerAvFreQual <- dtWorker$full %>% 
  group_by(ExternalReference) %>%
  summarise(
    n = n(),
    SumContactNL = sum(Contact_dum),
    PercContactNL = SumContactNL/n*100,
    SumContactNLAll = sum(number),
    AvAttitude = mean(thermometerDutch_1, na.rm = TRUE),
    AvQuality = mean(quality_overall_1, na.rm = TRUE)
  ) %>%
  mutate(
    WinSumContactNL = DescTools::Winsorize(SumContactNL),
    WinSumContactNLAll = DescTools::Winsorize(SumContactNLAll)
  )

# correlation panel 
pairs.panels.new(workerAvFreQual %>% select(SumContactNL, SumContactNLAll, AvQuality, AvAttitude), 
                 labels = c("Sum:\nNumer of beeps with Outgroup Contact (NL)", 
                            "Sum:\nNumber of Outgroup Contacts (NL)", 
                            "Mean:\nInteraction Quality",
                            "Mean:\nOutgroup Attitudes (NL)"))

# correlation panel with interaction sums winsorized
pairs.panels.new(workerAvFreQual %>% select(WinSumContactNL, WinSumContactNLAll, AvQuality, AvAttitude), 
                 labels = c("Sum:\nNumer of beeps with Outgroup Contact (NL)\n[Winsorized]", 
                            "Sum:\nNumber of Outgroup Contacts (NL)\n[Winsorized]", 
                            "Mean:\nInteraction Quality",
                            "Mean:\nOutgroup Attitudes (NL)"))
```

TL;DR: There is a medium sized correlation between the participants' Average Interaction Quality and their Average Outgroup Attitudes. Thus within our data participants with a higher quality outgroup interactions also held more positive attitudes towards that group. However, the frequency of intergroup interactions had no meaningfull correlation with either the average interaction quality or average outgroup attitudes.

```{r WorkerFreqQualReg}
# regression
lmworkerFreqInt <- lm(AvAttitude ~ SumContactNL * AvQuality, data = workerAvFreQual)
#summary(lmWorkerInteraction)
# apa_table(
#   apa_print(lmworkerFreqInt)$table, 
#   caption = "Regression across all measurement points [ignoring nested data]."
# ) 

summ(
  lmworkerFreqInt,
  confint = TRUE, 
  digits = 3,
  center = TRUE
     )

interactions::interact_plot(lmworkerFreqInt, pred = AvQuality, modx = SumContactNL, interval = TRUE, partial.residuals = TRUE)

interactions::johnson_neyman(lmworkerFreqInt, pred = AvQuality, modx = SumContactNL, alpha = .05)
```

TL;DR: We find that interaction quality is significantly related to higher outgroup attitudes (albeit with a small effect size). We also find that in our sample with an increasing number of interactions the positive effect of interaction quality becomes weaker. However, note that this is based on data aggregating all within participant nuances and is only the date of 21 people.

## Need Fulfillment

### Need fulfillment and Attitudes 

##### Unconditional model

make a model with only the data but a random intercept (unconditional model) for the outgroup interaction subset.

```{r workerOutPrep}
# see how large our outgroup interaction subset actually is 
tbl_cross(workerInteractionType, row=OutgroupInteraction, col=NonOutgroupInteraction, percent="row")

# create outgroup interaction subset
workerOutgroupInteraction <- workerInteractionType %>%
  filter(OutgroupInteraction == "Yes")
```

\begin{equation}
(\#eq:WorkerOutEmptyModel)
Attitude_{ti} = \gamma_{00} + u_{0i} + e_{ti} \\
\textrm{with}\ u_{0i} \sim \mathcal{N}(0,\tau_{00}^2)\ \textrm{and}\ e_{ti} \sim \mathcal{N}(0,\sigma^2)
\end{equation}

```{r Worker.Out.Null.Model.ML}
# Create and save Model
  Null.Out.ML.r = lme4::lmer(thermometerDutch_1~1 + (1|PID),data=workerOutgroupInteraction) #use optim if it does not converge
  Null.Out.ML = lme(thermometerDutch_1~1,random=~1|PID, data=workerOutgroupInteraction, control=list(opt="nlmimb")) #use optim if it does not converge

# Get summary with p-values (Satterthwaite's method)
  #summary(Null.ML.r) #or with the lme function
  summ(Null.Out.ML.r, digits = 3, center = TRUE)
  
# generate 95% parametric bootstrap CIs (and save them as a csv-file):
  #write.csv(confint(lmer(thermometerDutch_1~1 + (1|PID),data=df),
  #                  method="boot",nsim=1000, 
  #                  parallel = "multicore", ncpus = 4, seed = 42),
  #          "output/tables/ML-Null-CI.csv")

# Save variances
  v.out.null <- VarCorr(Null.Out.ML) # save variances
# The estimate of (between-group or Intercept variance, tau_{00}^2):
  tau <- as.numeric(v.out.null[1])
# and the estimate of (within-group or residual variancel, sigma^2) is:
  sigma <- as.numeric(v.out.null[2])
# The ICC estimate (between/between+within) is:
  ICC <- (as.numeric(v.out.null[1])/(as.numeric(v.out.null[1])+as.numeric(v.out.null[2])))
  ICC.Perc <- ((as.numeric(v.out.null[1])/(as.numeric(v.out.null[1])+as.numeric(v.out.null[2]))))*100
```

#### random intercept

\begin{equation}
(\#eq:AttitudeNeedEq)
Attitude_{ti} = \gamma_{00} + \gamma_{10}KeyNeedFulfill_{ti} + u_{0i} + e_{ti} \\
\textrm{with}\ u_{0i} \sim \mathcal{N}(0,\tau_{00}^2)\ \textrm{and}\ e_{ti} \sim \mathcal{N}(0,\sigma^2)
\end{equation}

```{r interceptAttKeyNeed}
# Create and save Model
  model.keyneed = lme(thermometerDutch_1 ~ keymotive_fulfillemt_1, random=~1|PID,data=workerOutgroupInteraction)

# Get summary with p-values (Satterthwaite's method)
  summ(lmer(thermometerDutch_1 ~ keymotive_fulfillemt_1 + (1|PID),data=workerOutgroupInteraction), 
       confint = TRUE, digits = 3, center = TRUE)

# Generate 95% parametric bootstrap CIs (and save them as a csv-file):
  #write.csv(confint(lmer(thermometerDutch_1 ~ Contact_dum + inNonDutch + (1|PID),data=df), 
  #                  method="boot",nsim=1000, parallel = "multicore", 
  #                  ncpus = 4, seed = 42),
  #          "output/tables/ML-Inter-CI.csv")

# Compare new model to previous step
  anova(Null.Out.ML, model.keyneed) %>%
    as.data.frame %>%
    select(-call) %>%
    kbl(., 
        #label = "",
        caption = "Worker: Model Comparison",
        format = "html", 
        linesep = "",
        booktabs = T,
        align = rep('c', ncol(.)),
        digits = 3)  %>%
  kable_styling(position = "left")

# Save variances
  v.keyneed <- lme4::VarCorr(model.keyneed) 

# The estimate of between-group (or Intercept variance) explained: 
  # Variance Explained = 1 – (Var with Predictor/Var without Predictor)
    v.keyneed.btw <- 1 - (as.numeric(v.keyneed[1])/as.numeric(v.out.null[1]))
    v.keyneed.btw.perc <-  (1 - (as.numeric(v.keyneed[1])/as.numeric(v.out.null[1])))*100
  # and the estimate of within-group (or residual variancel) explained is:
    v.keyneed.within <- 1 - (as.numeric(v.keyneed[2])/as.numeric(v.out.null[2]))
    v.keyneed.within.perc <- (1 - (as.numeric(v.keyneed[2])/as.numeric(v.out.null[2])))*100
```

#### check for random slope

\begin{equation}
(\#eq:AttitudeNeedRandEq)
Attitude_{ti} = \gamma_{00} + \gamma_{10}KeyNeedFulfill_{ti} + u_{0i} + u_{1i} + e_{ti}  \\
\textrm{with}\ \begin{bmatrix} u_{0i}\\ u_{1i}\end{bmatrix} \sim \mathcal{N}(0,\Omega_u): \Omega_u=\begin{bmatrix} \tau_{0}^2 & \\ \tau_{01} & \tau_{1}^2 \end{bmatrix} \textrm{and}\ e_{ti} \sim \mathcal{N}(0,\sigma^2)
\end{equation}

```{r slopesAttKeyNeed}
# Create and save Model (optimizer needed to reach convergence)
  model.keyneed.ran = lme(thermometerDutch_1~
                         keymotive_fulfillemt_1, 
                         random=~1+keymotive_fulfillemt_1|PID,
                       control=lmeControl(opt='optim'), data=workerOutgroupInteraction)

# Get summary with p-values (Satterthwaite's method) [+ save model for plotting]
  summ(model.keyneed.ran0 <- lmer(thermometerDutch_1 ~
                           keymotive_fulfillemt_1 + 
                           (1+keymotive_fulfillemt_1|PID), 
                         data=workerOutgroupInteraction), 
       confint = TRUE, digits = 3, center = TRUE)
  
# Generate 95% parametric bootstrap CIs (and save them as a csv-file):
  #write.csv(confint(model.ran0,
  #               method="boot",nsim=1000, 
  #               parallel = "multicore", ncpus = 4, seed = 42),
  #          "output/tables/ML-RandomSlopes-CI.csv")

# Compare new model to previous step
  anova(model.keyneed, model.keyneed.ran) %>%
    as.data.frame %>%
    select(-call) %>%
    kbl(., 
        #label = "",
        caption = "Worker: Model Comparison",
        format = "html", 
        linesep = "",
        booktabs = T,
        align = rep('c', ncol(.)),
        digits = 3)  %>%
  kable_styling(position = "left")

# Save variances
  v.keyneed.ran = lme4::VarCorr(model.keyneed.ran)

# The estimate of between-group (or Intercept variance) explained: 
  # Variance Explained = 1 – (Var with Predictor/Var without Predictor)
    v.keyneed.ran.btw <- 1 - (as.numeric(v.keyneed.ran[1])/as.numeric(v.keyneed[1]))
    v.keyneed.ran.btw.perc <-  (1 - (as.numeric(v.keyneed.ran[1])/as.numeric(v.keyneed[1])))*100
  # and the estimate of within-group (or residual variancel) explained is:
    v.keyneed.ran.within <- 1 - (as.numeric(v.keyneed.ran[2])/as.numeric(v.keyneed[2]))
    v.keyneed.ran.within.perc <- (1 - (as.numeric(v.keyneed.ran[2])/as.numeric(v.keyneed[2])))*100

# Assumption Checks: 
  diag = sjPlot::plot_model(model.keyneed.ran0, type = "diag")
  grid.arrange(diag[[1]],diag[[2]]$`PID`,diag[[3]],diag[[4]])
  
# Plot prediction model
  dat.new = workerOutgroupInteraction[,c("thermometerDutch_1","session","PID")]
  dat.new$measure = predict(model.keyneed.ran, workerOutgroupInteraction, re.form=NA)

  (t.ppt = ggplot(data=dat.new, aes(x=session, y=measure)) + 
    geom_line(alpha=1, color = "blue") +
    geom_line(aes(y = thermometerDutch_1), alpha=1)+
    facet_wrap(~PID, ncol = 6)+
    xlab("Time")+
    ylab("Outgroup Attitudes")+
    theme_bw())
  ggsave(filename = "Figures/Development per PPT Out Keyneed.png", t.ppt,
       width = 18, height = 12, dpi = 800, units = "cm", device='png')
  
  rm(dat.new)

```

### Need fulfillment and Interaction Quality 

#### random intercept

\begin{equation}
(\#eq:QualityNeedEq)
InteractionQuality_{ti} = \gamma_{00} + \gamma_{10}KeyNeedFulfill_{ti} + u_{0i} + e_{ti} \\
\textrm{with}\ u_{0i} \sim \mathcal{N}(0,\tau_{00}^2)\ \textrm{and}\ e_{ti} \sim \mathcal{N}(0,\sigma^2)
\end{equation}

#### check for random slope

\begin{equation}
(\#eq:QualityNeedRandEq)
InteractionQuality_{ti} = \gamma_{00} + \gamma_{10}KeyNeedFulfill_{ti} + u_{0i} + u_{1i} + e_{ti}  \\
\textrm{with}\ \begin{bmatrix} u_{0i}\\ u_{1i}\end{bmatrix} \sim \mathcal{N}(0,\Omega_u): \Omega_u=\begin{bmatrix} \tau_{0}^2 & \\ \tau_{01} & \tau_{1}^2 \end{bmatrix} \textrm{and}\ e_{ti} \sim \mathcal{N}(0,\sigma^2)
\end{equation}

### Need fulfillment, Interaction Quality, and Attitudes

#### random intercept

\begin{equation}
(\#eq:AttitudeQualityNeedEq)
Attitude_{ti} = \gamma_{00} + \gamma_{10}KeyNeedFulfill_{ti} + \gamma_{20}InteractionQuality_{ti} + u_{0i} + e_{ti} \\
\textrm{with}\ u_{0i} \sim \mathcal{N}(0,\tau_{00}^2)\ \textrm{and}\ e_{ti} \sim \mathcal{N}(0,\sigma^2)
\end{equation}

#### check for random slope

\begin{equation}
(\#eq:AttitudeQualityNeedRandEq)
Attitude_{ti} = \gamma_{00} + \gamma_{10}KeyNeedFulfill_{ti} + \gamma_{20}InteractionQuality_{ti} + u_{0i} + u_{1i} + e_{ti}  \\
\textrm{with}\ \begin{bmatrix} u_{0i}\\ u_{1i}\end{bmatrix} \sim \mathcal{N}(0,\Omega_u): \Omega_u=\begin{bmatrix} \tau_{0}^2 & \\ \tau_{01} & \tau_{1}^2 \end{bmatrix} \textrm{and}\ e_{ti} \sim \mathcal{N}(0,\sigma^2)
\end{equation}

#### Compare models

### Check for robustness

#### Interaction Type

##### random intercept

\begin{equation}
(\#eq:AttitudeNeedInteractionEq)
Attitude_{ti} = \gamma_{00} + \gamma_{10}KeyNeedFulfill_{ti} + \gamma_{20}OutgroupInteraction_{ti} + \gamma_{30}KeyNeedFulfillXOutgroupInteraction_{ti} + u_{0i} + e_{ti} \\
\textrm{with}\ u_{0i} \sim \mathcal{N}(0,\tau_{00}^2)\ \textrm{and}\ e_{ti} \sim \mathcal{N}(0,\sigma^2)
\end{equation}

##### check for random slope

\begin{equation}
(\#eq:AttitudeNeedInteractionRandEq)
Attitude_{ti} = \gamma_{00} + \gamma_{10}KeyNeedFulfill_{ti} + \gamma_{20}OutgroupInteraction_{ti} + \gamma_{30}KeyNeedFulfillXOutgroupInteraction_{ti}  + u_{0i} + u_{1i} + e_{ti}  \\
\textrm{with}\ \begin{bmatrix} u_{0i}\\ u_{1i}\end{bmatrix} \sim \mathcal{N}(0,\Omega_u): \Omega_u=\begin{bmatrix} \tau_{0}^2 & \\ \tau_{01} & \tau_{1}^2 \end{bmatrix} \textrm{and}\ e_{ti} \sim \mathcal{N}(0,\sigma^2)
\end{equation}

#### Other psychological needs

##### random intercept

\begin{equation}
(\#eq:AttitudeNeedSdtEq)
Attitude_{ti} = \gamma_{00} + \gamma_{10}KeyNeedFulfill_{ti} + \gamma_{20}Autonomy_{ti} + \gamma_{30}Competence_{ti} + \gamma_{40}Relatedness_{ti} + u_{0i} + e_{ti} \\
\textrm{with}\ u_{0i} \sim \mathcal{N}(0,\tau_{00}^2)\ \textrm{and}\ e_{ti} \sim \mathcal{N}(0,\sigma^2)
\end{equation}

##### check for random slope

\begin{equation}
(\#eq:AttitudeNeedSdtRandEq)
Attitude_{ti} = \\gamma_{00} + \gamma_{10}KeyNeedFulfill_{ti} + \gamma_{20}Autonomy_{ti} + \gamma_{30}Competence_{ti} + \gamma_{40}Relatedness_{ti} + u_{0i} + u_{1i} + e_{ti}  \\
\textrm{with}\ \begin{bmatrix} u_{0i}\\ u_{1i}\end{bmatrix} \sim \mathcal{N}(0,\Omega_u): \Omega_u=\begin{bmatrix} \tau_{0}^2 & \\ \tau_{01} & \tau_{1}^2 \end{bmatrix} \textrm{and}\ e_{ti} \sim \mathcal{N}(0,\sigma^2)
\end{equation}


# **Student Sample**

## Contact Hypothesis

## Need Fulfillment

# **Young Medical Professional Sample**

## Contact Hypothesis

## Allport's Conditions

## Need Fulfillment


# **Software Information**  
The full session information with all relevant system information and all loaded and installed packages is available in the collapsible section below.  

<details>
  <summary>System Info</summary>
  
  \renewcommand{\arraystretch}{0.8} <!-- decrease line spacing for the table -->
```{r Reproducibility-SessionInfo-R-environment, echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", out.width='100%', results='asis'}
  df_session_platform <- devtools::session_info()$platform %>% 
    unlist(.) %>% 
    as.data.frame(.) %>% 
    rownames_to_column(.)
  
  colnames(df_session_platform) <- c("Setting", "Value")
  
  kbl(
    df_session_platform, 
    booktabs = T, 
    align = "l",
    caption = "R environment session info for reproducibility of results" # complete caption for main document
  ) %>% 
    kable_classic(full_width = F, 
                  lightable_options = "hover", 
                  html_font = "Cambria") 
```
  \renewcommand{\arraystretch}{1} <!-- reset row height/line spacing -->
 </details>
 <br>
 <details>
  <summary>Package Info</summary>

\renewcommand{\arraystretch}{0.6} <!-- decrease line spacing for the table -->
```{r Reproducibility-SessionInfo-R-packages, echo=FALSE, message=FALSE, warning=FALSE, fig.align="center", out.width='100%', results='asis'}
df_session_packages <- devtools::session_info()$packages %>% 
  as.data.frame(.) %>% 
  filter(attached == TRUE) %>% 
  dplyr::select(loadedversion, date, source) %>% 
  rownames_to_column

colnames(df_session_packages) <- c("Package", "Loaded version", "Date", "Source")

kbl(
  df_session_packages, 
  booktabs = T, 
  align = "l",
  caption = "Package info for reproducibility of results" # complete caption for main document
) %>% 
  kable_classic(full_width = F, 
                  lightable_options = "hover", 
                  html_font = "Cambria") 
```
\renewcommand{\arraystretch}{1} <!-- reset row height/line spacing -->
</details>
<br>
<details>
  <summary>Full Session Info (including loaded but unattached packages --- for troubleshooting only)</summary>
    `r pander(sessionInfo(), compact = FALSE)`
</details>


--------------------------------------------------------------------

</br>  

# **References**  

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>

